---
title: "plm::plm() on Master-Thesis data"
author: "Michael Schmid"
date: "`r Sys.time()`"
header-includes:
   - \usepackage{cancel}
output:
  html_document: 
    code_folding: hide
    toc: yes
    toc_float:
      collapsed: no
    theme: yeti
---

```{=html}
<style type="text/css">

body, td {
   font-size: 13px;
   text-align: justify;
   <!-- font: Courier New -->
}
pre {
  font-size: 12px
}

div.blue { 
  background-color:#e6f0ff; 
  border-radius: 5px; 
  padding: 20px;
}

</style>
```


```{r setup, include=FALSE}
imsbasics::clc()
# source("../00_functions.R")

library(tidyverse)
library(shp)
library(plotly)
library(plm)    
library(stargazer)
library(lme4)
library(lmerTest) # allows lme4-models to create degrees of Freedom & p-values in summary
library(kableExtra)
library(modelsummary)
library(sjPlot)

options(width = 110) # goes optimal with pre font-size in html-chunk above
knitr::opts_chunk$set(echo = TRUE, fig.width = 10)
# Set render-directory to project-directory (important for loading of data in this RMD) 
# source: https://stackoverflow.com/questions/30237310/setting-work-directory-in-knitr-using-opts-chunksetroot-dir-doesnt-wor 
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```


```{r}
df_mt <- imsbasics::load_rdata("df_mt.RData", "Scripts_Michi/")
var_type <- attr(df_mt, "var_type")

# create a scaled dataset (where all numeric columns exept the first two are scaled)
df_mt_scaled <- df_mt[,3:ncol(df_mt)] %>% mutate_if(is.numeric, ~(scale(.) %>% as.vector))
df_mt_scaled <- cbind(id = df_mt$id, year = df_mt$year, df_mt_scaled)
# create a normalized dataset (where all numeric columns exept the first two are scaled)
df_mt_normalized <- BBmisc::normalize(df_mt[,3:ncol(df_mt)], method = "range", range = c(0, 1))
df_mt_normalized <- cbind(id = df_mt$id, year = df_mt$year, df_mt_normalized)

# create base_types, base_vars and base_formula (for modelling)
base_types <- c("lebenslage", "erwerbsarbeit", "carearbeit")
base_vars <- var_type$variable[var_type$type %in% base_types]
base_formula <- formula(paste("depression ~", paste(base_vars, collapse = " + ")))

models <- list()
```

# Intro

In diesem Script wollen wie die diversen Funktionalitäten des `plm-package` am 
importierten Datensatz anwenden. Bei der Modellierung fokussieren aus explorativen Gründen 
auf keine spezifische (theoriegeleitete) Formel ($y \sim x_1 + x_2 + ... + x_n$)  sondern 
versuchen, die wichtigen Variabeln der Typen "lebenslage", "erwerbsarbeit" und "carearbeit" 
miteinzubeziehen.  


```{r}
var_type
base_formula
```


# Modelle zur Analyse (Verständnis)

## `punbalancedness` - Unbalancedness

Wie stark ist der Datensatz balanciert resp. unbalancert? 

Der gesamte Datensatz, sowie der reduzierte Datensatz ("wichtige" Variabeln) haben 
einen "gamma"-Wert 0.66, "nu"-wert 0.79. (1 = balanciert / 0 = unbalanciert)

```{r}
## Balanciert? 
punbalancedness(df_mt, index = c("id", "year"))
punbalancedness(df_mt[,var_type$variable], index = c("id", "year"))
```

## `m.pvcm` - Variable Coefficient Models {.tabset}

Wir erzeugen ein Modell pro Individuum. Dies gibt eine Übersicht, wie die individuellen 
Regressionsgeraden (Regressions-Hyperebenen) aussehen würden. Diese Modelle besitzen 
eine schlechte Generalisierbarkeit (starker overfit), da sie die Grundgesamtheit der Daten vernachlässigt 
und immer nur ganz kleine "Mini-Modelle" pro Individuum generiert. Diese Modelle 
besitzen einen extrem guten Fit, da sie pro Individuum individuell 
zusammengeschnitten sind. 

Da die Basisformel `r length(base_vars)` unabhängige Variabeln besitzt, die geschätzt 
werden müssen, würden für Modelle auf individueller Ebene mind `r length(base_vars)` + 2 
Messungen benötigt (Aufgrund von Faktor-Variabeln ist die tatsächliche Zahl sogar noch 
grösser). Da die maximale Zeitspanne `r max(df_mt$year) - min(df_mt$year)` betr$gt, haben 
wir auch maximal `r max(df_mt$year) - min(df_mt$year)` Datenpunkte pro Person zu Verfügung. 

> The "within" model cannot work, as it needs T>(K+1) for estimating the separate regressions for each individual.

Aus diesem Grund betrachten wir hier jede Variable separat (`depression ~ x`) und 
verkelinern den Datensatz auf diejenigen Individuen, für die ein Modell tatsächlich 
geschätzt werden kann: 

 * für numerische unabhängige Variabeln -> alle Individuen mit mehr 3 o. mehr Beobachtungen.
 * für Faktor-Varaibeln mit 2 levels -> alle Individuen mit 4 o. mehr Beobachtungen.
 * für Faktor-Variabeln mit 3 o. mehr levels -> keine Betrchtung, da nur `ausbildung` betroffen, 
 welche immer zeitlich invariat ist und die Betrchtung keinen Sinn macht. 

Da jeweils immer nur einzelne lineare Zusammenhänge betrachtet werden, sollte bei 
der Interpretation keine fundamentalen Schlüsse gezogen werden.  

> Für Erkenntnisse, die globale Effekte auf individueller Ebene betreffen, kann diese 
Methode trotzdem einen wichtigen Beitrag liefern.

--- 

> Für numerische Variablen sehen wir den direkten linearen Zusammenhang von `depression` 
und der Variable 

> Für Faktor-Variabeln sehen wir nur Individuen, die einem Wechsel der Faktoren erlebt 
haben. z.B. für `ch_nationalitaet` sehen wir den Offset der `depression` für Personen 
die beide Zustände (`Ja` und `Nein`) erlebt haben. 

Interessante Variabeln: 

 * `einschraenkunge_weg_ges_zustand` zeigt eindeutig öfters einen positiven linearen Zusammenhang. 
 * `arbeit_zeit_nacht` hat öfters eine negativen linearen Zusammenhang. Dh: Personen, 
 welche sowohl Nachtarbeitszeit als auch keine Nachtarbeitszeit erlebt haben, hatten 
 grundsätzlich weniger `depression` angegeben -> das ist interessant, da es entgegen 
 der Intuition scheint. --> gibt jedoch viele Erklärungsmöglichkeiten (wünschenswerte 
 Nachtarbeit, freiwillige Nachtarbeit, positive Auswirkung der nachtarbeit auf andere 
 Lebensbereiche, ...)
 * `arbeit_zufriedenheit_atmosphaere` hat öfters einen negativen linearen Zusammenhang -> scheint intuitiv 
 * `pflege_angehoerige` hat öfters einen negativen linearen Zusammenhang. Dh: Personen, 
 die sowohl angehörige gepflegt haben als auch nicht, gaben grundsätzlich tiefere 
 Werte für `depression` an, wenn sie angehörige geplfegt haben --> interessant!! --> 
 Auch hier gibt es jedoch viele weitere Erklärungsmöglichkeiten.
 


```{r, results='asis', fig.width=10, warning=FALSE}
# see https://r.789695.n4.nabble.com/error-using-pvcm-on-unbalanced-panel-data-td1569157.html
pvcm_vars <- base_vars[!base_vars %in% "ausbildung"]

for (i in pvcm_vars) {
# for (i in c("alter", "partnerschaft")) {
  cat("\n\n###",i,"\n\n")

  if (class(df_mt %>% pull(i)) == "numeric") {
    n_obs_needed <- 3
    my_x_lab <- paste0("Individueller linearer Zusammenhang zwischen `",i,"` und `depression`")
  } else if (class(df_mt %>% pull(i)) == "factor") {
    assertthat::assert_that(length(levels(df_mt %>% pull(i))) == 2)
    lev1 <- levels(df_mt %>% pull(i))[1]
    lev2 <- levels(df_mt %>% pull(i))[2]
    my_x_lab <- paste0("Individueller Offset von `",lev2,"` im Vergleich zu `", lev1,"` bezgl. `depression`")
    n_obs_needed <- 4
  }

  df <- df_mt %>%
    filter(!is.na(depression)) %>% # abhängige Variable sollte nicht NA sein
    filter(!is.na(get(i))) %>% # unabhängige Variable sollte nicht NA sein
    group_by(id) %>%
    filter(n() >= n_obs_needed) # unabhängige variable sollte mind. n_obs_needed mal vorkommen

  # Variable Coefficient model
  m.pvcm <- pvcm(depression ~ get(i), df, model = "within")

  # pooltest: comparison to Pooling model
  m.pool_plm_compare <- plm(depression ~ get(i), df, model = "pooling")
  cat("\nPooltest for pooling-model")
  print(pooltest(m.pool_plm_compare, m.pvcm))
  # pooltest: comparison to FE model
  cat("\nPooltest for fixed-effect-model")
  m.fe_plm_compare <- plm(depression ~ get(i), df, model = "within")
  print(pooltest(m.fe_plm_compare, m.pvcm))



  # baseline in factor-regression is always the first level
  my_coefs <- coef(m.pvcm)[,2]

  h <- hist(my_coefs,
       breaks = seq(floor(min(my_coefs, na.rm = T))-0.5,ceiling(max(my_coefs, na.rm = T)) + 0.5,0.5),
       main = paste0("Variable ", i, " (",class(df_mt %>% pull(i)),")"),
       xlab = my_x_lab,  ylab = "Anzahl Personen")
  abline(v = median(my_coefs, na.rm = T), col = "red", lwd = 2)
  text(x = median(my_coefs, na.rm = T), y = max(h$counts), pos = 4, col = "red",
       labels = paste("Median: ", round(median(my_coefs, na.rm = T),2)))
}

# Fehlermeldung für gesamtes Modell: --> # Fehler in FUN(X[[i]], ...) : insufficient number of observations
# m.pvcm <- pvcm(base_formula, df_mt, model="within")
```


## `pooltest` - poolability

<div class = "blue">
`pooltest` tests the hypothesis that the same coefficients apply to each individual.
It is a standard F test, based on the comparison of a model obtained for the full sample 
("pooling" or "within") and a model based on the estimation of an equation for each individual 
(`pvcm`). The first argument of pooltest is a plm object. The second argument is a pvcm 
object obtained with model="within" or model = "pooling". If the first argument is a 
pooling model, the test applies to all the coefficients (including the intercepts), 
if it is a within model, different intercepts are assumed.
</div>


=> vgl. Grafiken oben. Es wurde für jedes Variable Coefficient Model ein Vergleich 
(`pooltest`) mit einem Pooling-Model und einem FE-Model (within) durchgeführt. 

 * Wenn `pooltest(pool, pvcm)` einen grossen p-Wert besitzt -> Nullhypothese wird angenommen 
 -> Die Koeffizienten & Intercept des pvcm sind stabil (= denen des Pooling-Modells) und 
 folglich wäre ein Pooling-Modell gleich gut. 
 **kommt nicht vor** (wäre auch erstaunlich, da immer Variabilität vorhanden ist in 
 den Verläufen der einzelnen Individuen). 
 * Wenn `pooltest(fe, pvcm)` einen grossen p-Wert besitzt -> Nullhypothese wird angenommen 
 -> Die Koeffizienten des pvcm (ohne Intercpt) sind stabil (= denen des FE-Modells) und 
 folglich wäre ein FE-Modell gleich gut. 
 **Für Faktor-Variabeln kommt dieser Fall oft vor, da** der Unterschied zwischen den 
 zwei Levels in vielen Fällen nicht exisitert (viele Individuen haben keinen Wechsel der 
 Faktor-Levels erlebt). Aus diesem Grund ist im Vergleich zur Grundgesamtheit der Anteil
 an Personen mit einem Wechsel klein. Für all diese Fälle ist ein gewöhnliches FE-Modell 
 gleich gut, weshalb am Ende das FE-Modell als gleichgut bewertet wird (resp. die 
 Koeffizienten als gleich bewertet werden mittels F-Test.)
 
 
## `plmtest` - Test for Effects 

<div class = "blue"> 
Test the presence of individual, time or twoways effects !!!

plmtest implements Lagrange multiplier tests of individual or/and time effects based on
the results of the pooling model. These Lagrange multiplier tests use only the residuals 
of the pooling model. The first argument of this function may be either a pooling model 
of class plm or an object of class formula describing the model. For inputted within 
(fixed effects) or random effects models, the corresponding pooling model is calculated 
internally first as the tests are based on the residuals of the pooling model.
</div>

**Spannend:**

 * gemäss diesem Test werden in den Residuen des Pooling-Modells (basierend auf unserer 
 Basis-Formel) keine signifikanten Zeit-Effekte mehr festgestellt. Dh: Das Pooling-Modell 
 ist in der Lage die zeitlichen Effekte relativ gut einzufangen. 

```{r}
cat("plm test for individual effect:")
plmtest(base_formula, data=df_mt, effect="individual")
cat("plm test for time effect:")
plmtest(base_formula, data=df_mt, effect="time")
cat("plm test for twoways effect:")
plmtest(base_formula, data=df_mt, effect="twoways")
```

# LMER-Basis-Modelle

## `dep ~ (1|year)` - Random Intercept year

Ein zeitlicher Effekt ist vorhanden und wird vom Random Effect aufgeschnappt.
Für die Analysen ist das nicht sinnvoll, da die zeitliche Trend eine Entwicklung ist
die wir **explizit** beachten wollen (und nicht als random Intercept mitberücksichtigen).

`depression ~ year + (1|year)`

Wenn wir die Zeit also explizit mitberücksichtien, verschwindet der zeitliche Trend
aus der random Intercept (der Effekt wurde von der Variable `year` "aufgesogen").
> Der zeitliche Trend verschwindet, wenn wir Zeit explizit ins Modell einführen.

`depression ~ (1|id) + (1|year)` 

Wenn wir random intercepts auf id's und zeit zulassen, wird die random intercept 
für Zeit  unterschiedlich. --> Manchmal grösser / manchmal kleiner pro Jahr. 

```{r, fig.width=10}
mean_dep_per_year <- df_mt %>% group_by(year) %>%
  summarize(mean_dep = mean(depression, na.rm = T)) %>%
  mutate(mean_dep_recentered = mean_dep - mean(mean_dep))
plot(mean_dep_per_year$year, mean_dep_per_year$mean_dep_recentered, type = "b", lwd = 2,
     xlab = "Jahr", ylab = "Random Effect",
     main = "Random Effect von Depression über die Zeit", ylim = c(-0.10, 0.12))
grid()

m.re_lme4_year1 <- lmer(depression ~ (1|year), data=df_mt, REML = F)
raneff <- ranef(m.re_lme4_year1)
lines(as.numeric(rownames(raneff$year)), raneff$year[,1], col = "blue", type = "b")
abline(h = 0)

m.re_lme4_year2 <- lmer(depression ~ year + (1|year), data=df_mt, REML = F)
raneff <- ranef(m.re_lme4_year2)
lines(as.numeric(rownames(raneff$year)), raneff$year[,1], col = "darkviolet", type = "b")

m.re_lme4_id_year <- lmer(depression ~ (1|id) + (1|year), data=df_mt, REML = F)
raneff <- ranef(m.re_lme4_id_year)
lines(as.numeric(rownames(raneff$year)), raneff$year[,1], col = "orange", type = "b")


legend("topleft",
  legend = c("RE-0: Jährliche Abweichung vom Gesamtmittelwert", "RE-1: depression ~ (1|year)",
             "RE-1: depression ~ year + (1|year)", "RE-2: depression ~ (1|year) + (1|id)"),
  col = c("black", "blue", "darkviolet", "orange"),
  pch = 1,  bty = "n", pt.cex = 2, cex = 1.2,
  text.col = c("black", "blue", "darkviolet", "orange"),
  inset = c(0.03, 0.03))

cat("Koeffizienten im Model: depression ~ (1|year)")
summary(m.re_lme4_year1)$coefficients
cat("Koeffizienten im Model: depression ~ year + (1|year)")
summary(m.re_lme4_year2)$coefficients
cat("Koeffizienten im Model: depression ~ (1|year) + (1|id)")
summary(m.re_lme4_id_year)$coefficients

cat("Random Intercepts für: depression ~ (1|year)")
plot_model(m.re_lme4_year1,type="re",sort.est = T, grid=F)
```


## `dep ~ (1|id)` - Random Intercept id

Für die ersten 100 Individuen.

Gesamthaft gibt es über die Individuen keinen Trend (resp. Effekt), weshalb die zusätzliche
Verwendung von `id` als explizite Variable keine Auswirkung auf das lmer-Modell hat. 

```{r, fig.width=10, warning=FALSE}
mean_dep_per_id <- df_mt %>% group_by(id) %>%
  summarize(mean_dep = mean(depression, na.rm = T)) %>%
  mutate(mean_dep_recentered = mean_dep - mean(mean_dep))
plot(mean_dep_per_id$mean_dep_recentered[1:100], type = "b",
     xlab = "Individuum", ylab = "Random Effect",
     main = "Random Effect von Depression über die Individuen")
grid()
m.re_lme4_id1 <- lmer(depression ~ (1|id), data=df_mt, REML = F)
raneff <- ranef(m.re_lme4_id1)
points(raneff$id[1:100,1], col = "blue", type = "b")
abline(h = 0)

m.re_lme4_id2 <- lmer(depression ~ id + (1|id), data=df_mt, REML = F)
raneff <- ranef(m.re_lme4_id2)
points(raneff$id[,1], col = "red", type = "b")
legend("topleft",
  legend = c("RE-0: Individuelle Abweichung vom Gesamtmittelwert", "RE-1: depression ~ (1|id)",
             "RE-1: depression ~ id + (1|id)"),
  col = c("black", "blue", "red"),
  pch = 1,
  bty = "n",
  pt.cex = 2,
  cex = 1.2,
  text.col = c("black", "blue", "red"),
  inset = c(0.03, 0.03))

cat("Koeffizienten im Model: depression ~ (1|id)")
summary(m.re_lme4_id1)$coefficients
cat("Koeffizienten im Model: depression ~ id + (1|id)")
summary(m.re_lme4_id2)$coefficients

cat("Random Intercepts für: depression ~ (1|id)")
plot_model(m.re_lme4_id1,type="re",sort.est = T, grid=F)
```


# Einfluss von Saklierung & Normalisierung {.tabset}

Am Beispiel eines Pooling & FE Modells wird aufgezeigt, dass weder Skalierung noch 
Normalisierung die Modellresultate (des plm-pooling Modells) beeinflussen. 
Geschätzte Koeffizienten und Konfidenzintervalle werden ensprechend skaliert - der 
Einfluss einzelner Paramter (gemessen am p-Wert) bleibt jedoch konsistent. 

## Pooling Model (plm)

```{r}
m.pool_plm <-            plm(base_formula, df_mt,            index = c("id","year"), model="pooling")
m.pool_plm_scaled <-     plm(base_formula, df_mt_scaled,     index = c("id","year"), model="pooling")
m.pool_plm_normalized <- plm(base_formula, df_mt_normalized, index = c("id","year"), model="pooling")

modelsummary(list(basic_Model = m.pool_plm, scaled_Model = m.pool_plm_scaled, 
                  normalized_Model = m.pool_plm_normalized), 
             estimate = "{estimate}{stars}  ({std.error})  ",
             statistic = " (P-value {p.value})", # "(Std: {std.error} / p: {p.value})",
             stars = FALSE)

rm(m.pool_plm, m.pool_plm_scaled, m.pool_plm_normalized)
```

## FE-Modell (plm)

```{r}
m.fe_plm <-            plm(base_formula, df_mt,            index = c("id","year"), model="within")
m.fe_plm_scaled <-     plm(base_formula, df_mt_scaled,     index = c("id","year"), model="within")
m.fe_plm_normalized <- plm(base_formula, df_mt_normalized, index = c("id","year"), model="within")

modelsummary(list(basic_Model = m.fe_plm, scaled_Model = m.fe_plm_scaled, 
                  normalized_Model = m.fe_plm_normalized), 
             estimate = "{estimate}{stars}  ({std.error})  ",
             statistic = " (P-value {p.value})", # "(Std: {std.error} / p: {p.value})",
             stars = FALSE)

rm(m.fe_plm, m.fe_plm_scaled, m.fe_plm_normalized)
```

## RE-Modell (lme4)
```{r}
base_formula_lme4 <- as.formula(paste("depression ~", paste(base_vars, collapse = " + "), "+ (1|id)"))

m.re_lme4 <-            lmer(base_formula_lme4, df_mt)
m.re_lme4_scaled <-     lmer(base_formula_lme4, df_mt_scaled)
m.re_lme4_normalized <- lmer(base_formula_lme4, df_mt_normalized)

modelsummary(list(basic_Model = m.re_lme4, scaled_Model = m.re_lme4_scaled, 
                  normalized_Model = m.re_lme4_normalized), 
             estimate = "{estimate}{stars}  ({std.error})  ",
             statistic = " (P-value {p.value})", # "(Std: {std.error} / p: {p.value})",
             stars = FALSE, 
             coef_omit = "SD")

rm(m.re_lme4, m.re_lme4_scaled, m.re_lme4_normalized, base_formula_lme4)
```

# Modell-Tests

## `pFtest` - individuelle/Zeit-Effekte? (Pooling vs. FE)

<div class = "blue"> 
Test für individuelle o. Zeit-Effekte basierend auf dem Vergleich von FE-Modell und 
Pool-Modell. 
</div>

Der Test schlägt vor, dass: 

 * individuelle Effekte vorhanden sind (fixed Effects für Individuen sind empfehlenswert)
 * zeitliche Effekte trendenziell nicht vorhanden sind (fixed Effekts für Zeit sind nicht empfehlenswert)
 * interagierende Effekte vorhanden sein könnten (ev. empfehlenswert, ev. reichen individuelle 
 Effekte aus)


```{r}
# pFtest(m.fe_plm, m.pool_plm) # -> is the same 
pFtest(base_formula, data = df_mt, model = "within", effect = "individual")

pFtest(base_formula, data = df_mt, model = "within", effect = "time")
pFtest(base_formula, data = df_mt, model = "within", effect = "twoways")
```


## `phtest` - Hausmann test

vgl. "Regressionsmodelle zur Analyse von Paneldaten" - Mendely.

Ist ein RE-Modell die gute Wahl (als Vergleich zum FE-Modell). 
Normales lineares Modell ist immer schlechter als ein normales Random Intercept Model, 
weshalb dieser Vergleich kein Sinn macht. Beim Hausmann Test wird deshalb das Random 
Intercept Modell mit dem Fixed Effects Modell verglichen. (Quelle: GSERM - Lab E - min 6)

 * Random Intercept Modell: Implizit unterschiedliche Intercepts (`y ~ x + (1|id)` random 
 intercept on `id`)
 * Fixed Effects Modell: Explizit unterschiedliche Intercepts (`y ~ x + id` dummy variable on `id`)

Interpretation bei kleinem p-Wert (GSERM - Lab E - min 14): Der Unterschied der zwei Modelle ist statistisch 
signifikant. Dh: Dummy-Variabeln alleine resp. random effects alleine kommen nicht 
zum selben Schluss --> dh: Es braucht random effects + Dummy-Variabeln o. Gruppen-Mittelwerte 
o. Group-Mean-Centering (random intercept alleine reicht nicht aus).  
  
**Falsche Interpretation** = Es braucht **nur** Dummy-Variabels resp. fixed Effects !! 


Vgl. [Wikipedia](https://de.wikipedia.org/wiki/Hausman-Spezifikationstest#:~:text=Der%20Hausman%2DSpezifikationstest%2C%20auch%20Durbin,unabh%C3%A4ngigen)%20Variablen%20und%20der%20St%C3%B6rgr%C3%B6%C3%9Fe.)  

Der Hausmanntest ist ein Test auf Endogenität. --> Test auf den Zusammenhang zwischen 
den erkärenden Variabeln und der Störgrösse.  

$$H_0: Cov(x,e)=0$$
Wird die Nullhypothese verworfen ist dies ein Zeichen für Endogenität --> Die 
Integration von Instrumental variables könnte angezeigt sein. 


```{r}
# phtest computes the Hausman test which is based on the comparison of two sets of estimates
# (see Hausman (1978)). Its main arguments are two panelmodel objects or a formula. A classical
# application of the Hausman test for panel data is to compare the fixed and the random effects
# models
phtest(base_formula, data = df_mt)
```
 

## `pwtest` - Unbeobachtete individuelle/Zeit-Effekte?

<div class = "blue"> 
Test: Unobserved (individual or time) effects?
--> test for individual error components and serially correlated idiosyncratic errors.

This semi-parametric test checks the null hypothesis of zero correlation between errors of the same group. Therefore, it has power both against individual effects and, more generally, any kind of serial correlation.

...There may also be serial correlation of the “usual” kind in the idiosyncratic error
terms, e.g., as an AR(1) process. By “testing for serial correlation” we mean testing
for this latter kind of dependence...
In plm we provide a number of joint, marginal and conditional ML-based tests, plus some
semiparametric alternatives which are robust vs. heteroskedasticity and free from distributional assumptions.
</div>

The test suggests that there are: 
 * unboserved effects on the individual level. -> (Endogeneity?)
 * no unboserved effect on the time level. 

```{r}
pwtest(base_formula, data=df_mt, effect = "individual")
pwtest(base_formula, data=df_mt, effect = "time")
```

## `pbsytest` - Serial Correlation or individual random effects

-> vgl. 2021_04_23_plm_olayaound.R

Bei unserer Datenbasis erwarten wir fast, dass diese Tests fehlschlagen... Das 
Basis-Modell ist nicht gut genug, um sämtliche Effekte zu erklären, weshalb gemäss 
Tests "immer" eine serielle Korrelation der Fehlerterme o. individuelle Random Effects 
übrig bleiben.

<div class = "blue"> 
The authors observe that, although suboptimal, these tests may help detecting the
right direction of the departure from the null, thus complementing the use of joint tests.
</div>


```{r}
pbsytest(base_formula, data=df_mt, test="ar") # AR(1) - serial correlation?
pbsytest(base_formula, data=df_mt, test="re") # individual random Effects? 
pbsytest(base_formula, data=df_mt, test="j") # Joint Effects (ser.corr & RE)
```


## `pbltest` - AR(1) or MA(1) Correlation in RE-Model

-> vgl. 2021_04_23_plm_olayaound.R

```{r}
pbltest(base_formula, data=df_mt, alternative="onesided")
pbltest(base_formula, data=df_mt, alternative="twosided")
```


## `pbgtest & pdwtest` - Serial Correlation in General 

 * pbgtest: Breusch-Godfrey Test of serial correlation for (the idiosyncratic component of) the errors in panel models.
 * pdwtest: Durbin-Watson Test of serial correlation for (the idiosyncratic component of) the errors in panel models.
 * pwartest: Wooldridge Test for serial correlation for (the idiosyncratic component of) the errors in fixed–effects panel models -  (AR(1) Errors).

```{r}
## Breusch–Godfrey Test for Panel Models
# pbgtest(model.xy, order = 2)


## Durbin-Watson Test for Panel Models (based on lmtest::dwtest() )
# pdwtest(model.xy)


## The test is applicable to any FE panel model, and in particular to “short” panels with small T and large n.
pwartest(base_formula, data=df_mt)


```


## ...

diverse weitere Tests... 



# Modelle mit der Basis-Formel

## `m.pool_plm`

Pooling Model

```{r, fig.height=6}
m.pool_plm <- plm(base_formula, df_mt, index = c("id","year"), model="pooling")
m.pool_plm_scaled <- plm(base_formula, df_mt_scaled, index = c("id","year"), model="pooling")
m.pool_plm_normalized <- plm(base_formula, df_mt_normalized, index = c("id","year"), model="pooling")
models <- rlist::list.append(models, m.pool_plm = m.pool_plm)
summary(m.pool_plm)
plot_model(m.pool_plm, show.values = TRUE, value.offset = .5)
```

Goldfeld-Quandt Test indicates, wheter the variances of two submodels are different. 
(Nullhypothesis: they are eual). If the null is rejected we can assume, that the 
variances differ for different submodels and that separate equations for each individual 
might do a better job. --> i.e. fixed effects, etc... 
```{r}
lmtest::gqtest(m.pool_plm, point=0.5, alternative="two.sided")
```


## `m.fd_plm`

 * Intercept = Der Wert für $y_{it} - y_{it-1}$, wenn $x_{it} - x_{it-1} = 0$. Dh. Wenn 
 sich innerhalb eines Jahres nichts veränder hat bei einer Person, dann steigt die 
 Depression grundsätzlich. 
 

```{r, fig.height=6}
m.fd_plm <- plm(base_formula, df_mt, index = c("id","year"), model="fd")
models <- rlist::list.append(models, m.fd_plm = m.fd_plm)
summary(m.fd_plm)
plot_model(m.fd_plm, show.values = TRUE, value.offset = .5)
```


## `m.fe_plm`

FE-Modell

```{r, fig.height=6}
m.fe_plm <- plm(base_formula, df_mt, index = c("id","year"), model="within")
models <- rlist::list.append(models, m.fe_plm = m.fe_plm)
summary(m.fe_plm)
plot_model(m.fe_plm, show.values = TRUE, value.offset = .5)
```

## `m.fe_plm_inst` {.tabset}

Instrumental Variables. 

Wir verwenden Variabeln die gemäss unserer Vermutung keinen direkten Einfluss auf 
Depression, jedoch einen inderekten haben können (über eine andere Variable, welche 
wir als *endogen* betrachten - korreliert mit dem Fehlerterm). 

Beispiele: 

 * `ausbildung` (Lebenslage) als Instrument für `arbeit_zeit_wochenstunden` (Erwerbsarbeit) 
 * `kinder_betreuung` (Carearbeit) als Instrument für `haushaltsaequivalenzeinkommen` (Lebenslage). 
 * `arbeit_qualifikation` (Erwerbsarbeit) als instrument für `arbeit_einbezug_entscheidungen` (Erwerbsarbeit). 

Kandidaten für einen inderekten Einfluss auf `depression` (Instrumente): 

 * ausbildung 
 * alter
 * geschlecht 
 * ch_nationalitaet
 * haushaltsaequivalenzeinkommen
 * arbeit_qualifikation
 * arbeit_zeit_wochenstunden
 * arbeit_zeit_nacht
 * hausarbeit_wochenstunden
 * kinder_betreuung
 * pflege_angehoerige
 
Kandidaten für einen direkten Einfluss auf `depression`:
 
 * einschraenkung_weg_ges_zustand
 * partnerschaft 
 * tod_person
 * arbeit_einbezug_entscheidungen
 * arbeit_zeit_überstunden
 * arbeit_intensitaet
 * arbeit_zufriedenheit_atmosphaere


> Allgemein --> grosse Change, wenn mehr Variabeln über das "Wie fühlt sich eine Person" 
vorhanden wären. Diese könnten als direkte endogene Variabeln betrachtet werden und 
die aktuell vorhandnen Variabeln könnten vermehrt als Instrumente (Z) betrachtet werden, welche 
die individuelle Gefühlslage (X) beeinflusen. 

Im Falle unserer Modelle (vgl. unten) sind keine Erkenntnisse möglich. Es zeigt sich, 
dass sämtliche geschätzten Koeffizienten keine statistische Signifikanz aufweisen. Dies 
ist nicht erstaunlich, da sämtliche Instrumente deutlich zu schwach sind. 
($R^2$ bei der Betrachtung von Z -> X ist deutlich zu klein. Dh: die Instrumente 
erklären einen viel zu kleinen Teil der Variantion von X. Deshalb funktioniert die 
zweistufige Regression in diesem Fall unglaublich schlecht. )

**The instrumental variables** --> https://bookdown.org/ccolonescu/RPoE4/random-regressors.html#the-instrumental-variables-iv-method 
**checking Instrumental Validtiy** --> https://www.econometrics-with-r.org/12-3-civ.html

weitere Möglichkeiten mit `AER::ivreg()` -> Example on https://www.econometrics-with-r.org/12-4-attdfc.html 

### Alle Variabeln sind Instrumente

```{r}
instrumental_formula1 <- formula(paste("depression ~", 
                                      paste(base_vars, collapse = " + "),  " | ", 
                                      paste(base_vars, collapse = " + ")))

print(instrumental_formula1)

m.fe_plm_inst1 <- plm(instrumental_formula1, df_mt, index = c("id","year"), model="within")
models <- rlist::list.append(models, m.fe_plm_inst1 = m.fe_plm_inst1)
summary(m.fe_plm_inst1)
plot_model(m.fe_plm_inst1, show.values = TRUE, value.offset = .5)
```

### spezifische Instrumente 

```{r}

instr_vars <- c(1,2,3,4,6,10,11,13,16,17,18)
instrumental_formula2 <- formula(paste("depression ~", 
                                      paste(base_vars[-instr_vars], collapse = " + "),  " | ", 
                                      paste(base_vars[instr_vars], collapse = " + ")))

print(instrumental_formula2)

m.fe_plm_inst2 <- plm(instrumental_formula2, df_mt, index = c("id","year"), model="within")
models <- rlist::list.append(models, m.fe_plm_inst2 = m.fe_plm_inst2)
summary(m.fe_plm_inst2)
plot_model(m.fe_plm_inst2, show.values = TRUE, value.offset = .5)
```


## `m.re_plm`

RE-Modell (Definition von PLM -> Random Intercept)

46% of variance components are on individual level (between) / 54% on the idiosyncratic
level (within).

```{r, fig.height=6}
m.re_plm <- plm(base_formula, df_mt, index = c("id","year"), model="random")
models <- rlist::list.append(models, m.re_plm = m.re_plm)
summary(m.re_plm)
plot_model(m.re_plm, show.values = TRUE, value.offset = .5)
```


## `m.re-kv_plm`

Re-Modell with group-mean Centering --> hybrides Modell. 

```{r, fig.height=6}
df <- df_mt[,colnames(df_mt) %in% attr(df_mt, "var_type")$variable]
df_numeric <- df %>% select_if(is.numeric)
vars_numeric <- colnames(df_numeric)[!colnames(df_numeric) %in% "depression"]
# group-mean centering for all variables exept "id" and "year"
vars_mc <- colnames(df %>% select_if(is.numeric))
vars_mc <- vars_numeric[! vars_numeric %in% c("id", "year", "depression", "cluster", "person_haushalt")]
vars_mc_formula <- c()
for (i in vars_mc) {
  vars_mc_formula <- c(vars_mc_formula, paste0(i,"_mn"), paste0(i, ""))

}
# Mean centered dataset!
df_mt_mc <- rockchalk::gmc(df_mt, vars_mc, by = "id")

# create formula for group-meaned model.
vars_not_mc <- base_vars[!base_vars %in% vars_mc]
assertthat::assert_that(length(vars_mc) + length(vars_not_mc) == length(base_vars))


formula_mc <- formula(paste("depression ~",
                            paste(vars_not_mc, collapse = " + "), " + ",
                            paste(vars_mc_formula, collapse = " + ")))
print("Mean centered formula for mean-centered data:")
print(formula_mc)


m.re_kv_plm <- plm(formula_mc, df_mt_mc, index = c("id","year"), model="random")
models <- rlist::list.append(models, m.re_kv_plm = m.re_kv_plm)
summary(m.re_kv_plm)
plot_model(m.re_kv_plm, show.values = TRUE, value.offset = 0.4,
           value.size = 4, axis.lim = c(-1,1),
           title = "Effekte im RE-KV-Modell",
           axis.title = "Effektschätzung_inkl_95%-Konfidenzintervall", ci.lvl = 0.95)


# Hausmann-Test for demeaned-data
phtest(formula_mc, data = df_mt_mc)

```


## `m.re_nlme`

RE-Modell (mit `nlme::lme()`) -> Formulierung als Random intercept auf "id". Die
Koeffizienten sollten ähnlich sein zu diesen in `m.re_plm`

```{r, fig.height=6}
m.re_nlme <- nlme::lme(base_formula, data=df_mt, random=~1|id, na.action = na.omit)
models <- rlist::list.append(models, m.re_nlme = m.re_nlme)

summary(m.re_nlme)
plot_model(m.re_nlme, show.values = TRUE, value.offset = .5)
```

## `m.re_lme4`

```{r, fig.height=6}
base_formula_lme4 <- as.formula(paste("depression ~", paste(base_vars, collapse = " + "), "+ (1|id)"))

m.re_lme4 <- lmer(base_formula_lme4, data=df_mt)
models <- rlist::list.append(models, m.re_lme4 = m.re_lme4)

summary(m.re_lme4)
plot_model(m.re_lme4, show.values = TRUE, value.offset = .5)
```

## `m.re_lme4_1`

Random intercept auf allen Faktorvariabeln! --> idee: Das könnte uns eine Quantifizierung 
geben, inwiefern diese Variabeln tatsächlich relevant sind. Funktioniert nicht, da 
das Modell nicht konvergiert. 

Höchstwahrscheinlich sind das zu viele Random intercepts. 

```{r}
factor_vars <- names(df_mt)[sapply(df_mt, is.factor)]

formula_lme4_1 <- as.formula(paste("depression ~", paste(base_vars, collapse = " + "), " + ",
                                   paste0("(1|",factor_vars,")", collapse = " + ")))
formula_lme4_1

# m.re_lme4_1 <- lmer(formula_lme4_1, data=df_mt)
# models <- rlist::list.append(models, m.re_lme4_1 = m.re_lme4_1)
# summary(m.re_lme4_1)
# plot_model(m.re_lme4_1, show.values = TRUE, value.offset = .5)
```

## `m.re_lme4_2`

Random slope on alter 

```{r, fig.height=6}
formula_lme4_2 <- as.formula(paste("depression ~", paste(base_vars, collapse = " + "), 
                                   "+ (alter|id)"))

m.re_lme4_2 <- lmer(formula_lme4_2, data=df_mt)
models <- rlist::list.append(models, m.re_lme4_2 = m.re_lme4_2)

summary(m.re_lme4_2)
plot_model(m.re_lme4_2, show.values = TRUE, value.offset = .5)
```


## `m.re_lme4_3`

Random slope on arbeit_zufriedenheit_atmosphaere  

```{r, fig.height=6}
formula_lme4_3 <- as.formula(paste("depression ~", paste(base_vars, collapse = " + "), 
                                   "+ (arbeit_zufriedenheit_atmosphaere|id)"))

m.re_lme4_3 <- lmer(formula_lme4_3, data=df_mt)
models <- rlist::list.append(models, m.re_lme4_3 = m.re_lme4_3)

summary(m.re_lme4_3)
plot_model(m.re_lme4_3, show.values = TRUE, value.offset = .5)
```

## `m.re_lme4_glmer`

Random intercept on id & family poission().

**does not converge** on normal data. (error message)
**does not converge** on scaled data. (abort after 10h)

See here for inputs on convergence issues: https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html

```{r, fig.height=6}
# base_formula_lme4


# strictControl <- glmerControl(optCtrl = list(optimizer = "NLOPT_LN_NELDERMEAD",
#                                              xtol_abs = 1e-12, ftol_abs = 1e-12))

# m.re_lme4_glmer <- glmer(base_formula_lme4, data=df_mt_normalized, family = poisson()) # control = strictControl
# models <- rlist::list.append(models, m.re_lme4_glmer = m.re_lme4_glmer)
# 
# 
# summary(m.re_lme4_glmer)
# plot_model(m.re_lme4_glmer, show.values = TRUE, value.offset = .5)
```


## Summary

```{r}
modelsummary(models, # models[c(1,2,3,4,5)]
             estimate = "{estimate}{stars}",
             statistic = "({std.error})", # "(Std: {std.error} / p: {p.value})",
             stars = FALSE) %>%
  column_spec(c(5,6), background = '#E5FFCC') %>% 
  column_spec(c(7,8,9), background = '#CCFFFF') 

# see https://vincentarelbundock.github.io/modelsummary/articles/appearance.html
# modelsummary(models, output = "table.docx")
```



# Models with multiple membership?
vgl. GSERM. vielleicht interessant, aber wir wollen noch andere Arten von Modellen 
ausprobieren und etwas von der "linearen resp. multilevel Regression" weggkommen. 


# jmcm 

> Autoregressive Analyse pro Cluster (vgl. separates Dokument 2021_05_16_jmcm_playaround.Rmd)


```{r}

```

# vcrpart

> varying coefficinet models based on glmer & mixed models 
(vgl. separates Dokument 2021_05_16_vcrpart_playaound.R)
